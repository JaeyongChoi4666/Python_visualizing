{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4309169d-ff98-4caf-bb64-e33993d34d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape= (10, 1) , t_data.shape= (10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data=np.array([2,4,6,8,10,12,14,16,18,20]).reshape(10,1)\n",
    "t_data=np.array([0,0,0,0,0,1,1,1,1,1]).reshape(10,1)\n",
    "\n",
    "print(\"x_data.shape=\",x_data.shape,\", t_data.shape=\",t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b90f8a-6b93-4098-9e09-1d1775404887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= [[0.37122648]] , W.shape= (1, 1) , b= [0.53518048] , b.shape= (1,)\n"
     ]
    }
   ],
   "source": [
    "W=np.random.rand(1,1)\n",
    "b=np.random.rand(1)\n",
    "print(\"W=\",W, \", W.shape=\",W.shape, \", b=\",b,\", b.shape=\",b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62d9930-bcfb-460c-81a6-b0d0c201ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5146e26-a6e0-4fac-b737-bbbc812f3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    delta = 1e-7\n",
    "    \n",
    "    z = np.dot(x,W)+b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return -np.sum( t*np.log(y+delta) + (1-t)*np.log((1-y)+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081001f2-9737-4931-9b5c-e63e305e9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):    # 수치미분 debug version\n",
    "    delta_x = 1e-4 \n",
    "    grad = np.zeros_like(x)\n",
    "#     print(\"debug 1. initial input variable =\", x)   \n",
    "#     print(\"debug 2. initial grad =\", grad) \n",
    "#     print(\"=======================================\")\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "#         print(\"debug 3. idx = \", idx, \", x[idx] = \", x[idx])   \n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)   # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x)   # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "                \n",
    "#         print(\"debug 4. grad[idx] = \", grad[idx])   \n",
    "#         print(\"debug 5. grad = \", grad) \n",
    "#         print(\"=======================================\")\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4c6731-7156-4360-b12d-e418fc1f323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d2075a-1fc5-4177-8290-610f6df9034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y >= 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c3fe40a-da0d-4eee-9b4c-c96a40bcf6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  14.300741711898343 Initial W =  [[0.37122648]] \n",
      " , b =  [0.53518048]\n",
      "step =  0 error value =  7.437843574484569 W =  [[0.08928897]] , b =  [0.5043708]\n",
      "step =  400 error value =  2.265867004268756 W =  [[0.36260028]] , b =  [-3.59908231]\n",
      "step =  800 error value =  1.6481507029983413 W =  [[0.49628694]] , b =  [-5.1556612]\n",
      "step =  1200 error value =  1.3770952921190607 W =  [[0.58689585]] , b =  [-6.19348418]\n",
      "step =  1600 error value =  1.2152313346294812 W =  [[0.65761179]] , b =  [-6.99661631]\n",
      "step =  2000 error value =  1.1037775438750075 W =  [[0.71662897]] , b =  [-7.66332614]\n",
      "step =  2400 error value =  1.0204819977382427 W =  [[0.76784356]] , b =  [-8.23975753]\n",
      "step =  2800 error value =  0.9548371763881565 W =  [[0.8134337]] , b =  [-8.75148373]\n",
      "step =  3200 error value =  0.901147932193933 W =  [[0.85474943]] , b =  [-9.21425195]\n",
      "step =  3600 error value =  0.8560205654514836 W =  [[0.89268983]] , b =  [-9.63849553]\n",
      "step =  4000 error value =  0.8172875683304354 W =  [[0.92788623]] , b =  [-10.03151034]\n",
      "step =  4400 error value =  0.7834892203660084 W =  [[0.96080042]] , b =  [-10.39861423]\n",
      "step =  4800 error value =  0.753600439716818 W =  [[0.99178124]] , b =  [-10.74381282]\n",
      "step =  5200 error value =  0.7268765422698837 W =  [[1.02109923]] , b =  [-11.07020493]\n",
      "step =  5600 error value =  0.7027611668676534 W =  [[1.04896887]] , b =  [-11.38024149]\n",
      "step =  6000 error value =  0.6808287431406738 W =  [[1.07556329]] , b =  [-11.67589751]\n",
      "step =  6400 error value =  0.6607471433118384 W =  [[1.10102449]] , b =  [-11.95878994]\n",
      "step =  6800 error value =  0.6422526373929551 W =  [[1.12547052]] , b =  [-12.23026099]\n",
      "step =  7200 error value =  0.6251326235129789 W =  [[1.14900069]] , b =  [-12.49143823]\n",
      "step =  7600 error value =  0.6092134271569695 W =  [[1.17169942]] , b =  [-12.74327896]\n",
      "step =  8000 error value =  0.5943514960255383 W =  [[1.19363912]] , b =  [-12.98660362]\n",
      "step =  8400 error value =  0.5804269246382756 W =  [[1.21488247]] , b =  [-13.22212121]\n",
      "step =  8800 error value =  0.5673386116490912 W =  [[1.23548407]] , b =  [-13.45044914]\n",
      "step =  9200 error value =  0.5550005832729582 W =  [[1.25549184]] , b =  [-13.67212865]\n",
      "step =  9600 error value =  0.5433391638750518 W =  [[1.2749481]] , b =  [-13.88763722]\n",
      "step =  10000 error value =  0.5322907715557339 W =  [[1.2938904]] , b =  [-14.09739842]\n",
      "step =  10400 error value =  0.5218001813171956 W =  [[1.31235226]] , b =  [-14.30178996]\n",
      "step =  10800 error value =  0.5118191425340775 W =  [[1.33036373]] , b =  [-14.50115027]\n",
      "step =  11200 error value =  0.5023052680468113 W =  [[1.34795188]] , b =  [-14.69578391]\n",
      "step =  11600 error value =  0.4932211337398125 W =  [[1.36514118]] , b =  [-14.88596607]\n",
      "step =  12000 error value =  0.4845335428505594 W =  [[1.38195382]] , b =  [-15.07194637]\n",
      "step =  12400 error value =  0.4762129203903146 W =  [[1.39841003]] , b =  [-15.253952]\n",
      "step =  12800 error value =  0.46823281120922333 W =  [[1.41452829]] , b =  [-15.43219042]\n",
      "step =  13200 error value =  0.46056946128021453 W =  [[1.43032552]] , b =  [-15.60685168]\n",
      "step =  13600 error value =  0.45320146629617536 W =  [[1.4458173]] , b =  [-15.77811036]\n",
      "step =  14000 error value =  0.4461094750929276 W =  [[1.46101795]] , b =  [-15.94612728]\n",
      "step =  14400 error value =  0.4392759380169454 W =  [[1.47594074]] , b =  [-16.11105093]\n",
      "step =  14800 error value =  0.4326848923625374 W =  [[1.49059792]] , b =  [-16.2730188]\n",
      "step =  15200 error value =  0.4263217785586552 W =  [[1.50500089]] , b =  [-16.43215843]\n",
      "step =  15600 error value =  0.42017328200068743 W =  [[1.51916023]] , b =  [-16.58858842]\n",
      "step =  16000 error value =  0.4142271963796265 W =  [[1.53308583]] , b =  [-16.74241924]\n",
      "step =  16400 error value =  0.40847230511858734 W =  [[1.5467869]] , b =  [-16.89375404]\n",
      "step =  16800 error value =  0.40289827813102 W =  [[1.56027206]] , b =  [-17.04268928]\n",
      "step =  17200 error value =  0.3974955815999517 W =  [[1.5735494]] , b =  [-17.18931531]\n",
      "step =  17600 error value =  0.3922553988686897 W =  [[1.5866265]] , b =  [-17.33371694]\n",
      "step =  18000 error value =  0.3871695608502085 W =  [[1.59951049]] , b =  [-17.47597384]\n",
      "step =  18400 error value =  0.3822304846219721 W =  [[1.61220809]] , b =  [-17.61616104]\n",
      "step =  18800 error value =  0.3774311190837273 W =  [[1.62472564]] , b =  [-17.75434924]\n",
      "step =  19200 error value =  0.37276489673175706 W =  [[1.6370691]] , b =  [-17.89060519]\n",
      "step =  19600 error value =  0.3682256907456661 W =  [[1.64924414]] , b =  [-18.02499198]\n",
      "step =  20000 error value =  0.3638077767049183 W =  [[1.66125609]] , b =  [-18.15756931]\n",
      "step =  20400 error value =  0.3595057983514923 W =  [[1.67311004]] , b =  [-18.28839375]\n",
      "step =  20800 error value =  0.3553147368989157 W =  [[1.6848108]] , b =  [-18.41751896]\n",
      "step =  21200 error value =  0.3512298834579566 W =  [[1.69636293]] , b =  [-18.54499592]\n",
      "step =  21600 error value =  0.347246814208797 W =  [[1.70777078]] , b =  [-18.67087306]\n",
      "step =  22000 error value =  0.34336136799934713 W =  [[1.71903849]] , b =  [-18.7951965]\n",
      "step =  22400 error value =  0.3395696260919034 W =  [[1.73017]] , b =  [-18.91801017]\n",
      "step =  22800 error value =  0.33586789381678617 W =  [[1.74116907]] , b =  [-19.03935594]\n",
      "step =  23200 error value =  0.33225268392251933 W =  [[1.75203929]] , b =  [-19.1592738]\n",
      "step =  23600 error value =  0.32872070143821414 W =  [[1.76278408]] , b =  [-19.27780193]\n",
      "step =  24000 error value =  0.3252688298872961 W =  [[1.77340674]] , b =  [-19.39497683]\n",
      "step =  24400 error value =  0.32189411871066603 W =  [[1.78391039]] , b =  [-19.51083345]\n",
      "step =  24800 error value =  0.31859377177472714 W =  [[1.79429804]] , b =  [-19.62540522]\n",
      "step =  25200 error value =  0.31536513685434275 W =  [[1.80457257]] , b =  [-19.73872423]\n",
      "step =  25600 error value =  0.31220569599347614 W =  [[1.81473675]] , b =  [-19.8508212]\n",
      "step =  26000 error value =  0.3091130566571248 W =  [[1.82479322]] , b =  [-19.96172565]\n",
      "step =  26400 error value =  0.30608494359855604 W =  [[1.83474454]] , b =  [-20.07146593]\n",
      "step =  26800 error value =  0.30311919137325877 W =  [[1.84459316]] , b =  [-20.18006926]\n",
      "step =  27200 error value =  0.30021373743937946 W =  [[1.85434143]] , b =  [-20.28756186]\n",
      "step =  27600 error value =  0.2973666157904453 W =  [[1.86399161]] , b =  [-20.39396891]\n",
      "step =  28000 error value =  0.2945759510717948 W =  [[1.87354591]] , b =  [-20.49931471]\n",
      "step =  28400 error value =  0.2918399531377005 W =  [[1.8830064]] , b =  [-20.60362262]\n",
      "step =  28800 error value =  0.28915691200989085 W =  [[1.89237514]] , b =  [-20.7069152]\n",
      "step =  29200 error value =  0.28652519320286995 W =  [[1.90165407]] , b =  [-20.80921419]\n",
      "step =  29600 error value =  0.2839432333842695 W =  [[1.91084508]] , b =  [-20.91054058]\n",
      "step =  30000 error value =  0.28140953634206517 W =  [[1.91994999]] , b =  [-21.01091463]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2  # 발산하는 경우, 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)  # f(x) = loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "for step in  range(30001):  \n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d720c99e-aed6-4708-b8d7-6a3d1f5a943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.37983407e-07]] 0\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(3) \n",
    "\n",
    "print(real_val, logical_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
